{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using Gemini model with LLamaIndex to make an AI customer service agent. It can respond to queries and take orders. The menu and other restaurant info is in the system prompt. \n",
    "\n",
    "There is pydantic object named Response with a key response and a key status. response key holds the llm response, status key holds the status of system. If customer asks a general query, it is normal, if they are trying to order somethihng it is order, if they are done with order, it is done. \n",
    "\n",
    "When customer starts ordering, kick in the order module that keeps track of all the items added to cart. Whenever the customers adds something, ask if they want something else, if they say no or something that suggests that they are done, mark the order complete, tell them the summary and ask for their name and phone number, end the session and return the order in json. \n",
    "\n",
    "This should follow a general order taking conversation, asks for customization or other details if they are provided in menu such as chicken optiins and spice levels, also ask for other instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"Add api key\"\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./restaurant_details.txt\", \"r\") as f:\n",
    "    detail = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"You are a customer service agent at a restaurant. Your job is to answer customer questions or take order if they want to place an order. Menu and other details of restuarant are as follows.\n",
    "When someone asks about menu. Give them an overview, don't go in details. Go in details only if asked.\n",
    "{detail}\n",
    "\n",
    "Respond according to the given JSON schema.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = llm.complete(f\"{SYSTEM_PROMPT}\\nOkay, I want a loaded fries\" )\n",
    "# print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# response_json = json.loads(resp.text)\n",
    "# response = response_json[\"response\"]\n",
    "# order = response_json[\"order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "cred = credentials.Certificate(\"ezrai-4ccbe-firebase-adminsdk-fbsvc-ef41610e60.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "def push_order(order):\n",
    "    \"\"\"Pushes multiple dummy orders to Firestore.\"\"\"\n",
    "    orders_ref = db.collection(\"orders\")\n",
    "    ct = orders_ref.count()\n",
    "    count_query = orders_ref.count()\n",
    "    count_result = count_query.get()\n",
    "\n",
    "    # Extract count\n",
    "    ct = count_result[0][0].value\n",
    "    orders_ref.document(str(ct+1)).set({\"items\":order})\n",
    "\n",
    "    print(f\"âœ… Order {order} added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamza.mahmood/Developer/ezrai/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, Union\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Response Schema\n",
    "class Response(BaseModel):\n",
    "    response: str\n",
    "    status: str  # \"normal\", \"ordering\", or \"done\"\n",
    "llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    ")\n",
    "structured_llm = llm.as_structured_llm(output_cls=Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "\n",
    "class Item(BaseModel):\n",
    "    ordered: bool\n",
    "    name: str\n",
    "    quantity: int\n",
    "\n",
    "def preprocess_and_parse(input_string):\n",
    "    # Remove markdown code block indicators if present\n",
    "    # json_string = re.sub(r'^```json\\s*|\\s*```$', '', input_string.strip())\n",
    "    json_pattern = r'\\{(?:[^{}]|\\{[^{}]*\\})*\\}|\\[(?:[^\\[\\]]|\\[[^\\[\\]]*\\])*\\]'\n",
    "    json_match = re.search(json_pattern, input_string)\n",
    "    \n",
    "    if not json_match:\n",
    "        return None\n",
    "    \n",
    "    json_str = json_match.group(0)\n",
    "    \n",
    "    # Use regex to find the \"value\" field and process its numeric value\n",
    "    processed_string = re.sub(\n",
    "        r'\"quantity\"\\s*:\\s*\"?(\\d+(?:,\\d+)*(?:\\.\\d+)?)\"?', \n",
    "        lambda m: f'\"quantity\": {m.group(1).replace(\",\", \"\")}',\n",
    "        json_str\n",
    "    )\n",
    "       \n",
    "    # Parse the processed string as JSON\n",
    "    print(f\"processed string: \\n{processed_string}\")\n",
    "    return json.loads(processed_string)\n",
    "\n",
    "# Chat Handler to manage conversation history and process query\n",
    "class ChatHandler:\n",
    "    def __init__(self, llm):\n",
    "        self.history = []\n",
    "        self.current_status = \"normal\"  # Initially in \"normal\" status\n",
    "        self.order_items = {}  # Track items separately\n",
    "        self.llm = llm\n",
    "\n",
    "    def add_to_history(self, user_input, ai_response):\n",
    "        \"\"\"Store conversation history.\"\"\"\n",
    "        self.history.append(f\"User: {user_input}\")\n",
    "        self.history.append(f\"AI: {ai_response}\")\n",
    "\n",
    "        # Limit history to avoid excessive token use\n",
    "        if len(self.history) > 10:\n",
    "            self.history = self.history[-10:]\n",
    "\n",
    "    def process_query(self, query) -> Response:\n",
    "        \"\"\"Forces every response into Response format while keeping chat history.\"\"\"\n",
    "        history_str = \"\\n\".join(self.history)\n",
    "        prompt = f\"\"\"\n",
    "        {SYSTEM_PROMPT}\n",
    "\n",
    "        Chat History:\n",
    "        {history_str}\n",
    "\n",
    "        Current Status: {self.current_status}\n",
    "\n",
    "        User: {query}\n",
    "        \n",
    "        Respond according to schema: {Response.model_json_schema()}\n",
    "        ordering if the intent of customer is to order, done if they are done ordering, normal for all other queries\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        raw_response = self.llm.complete(prompt).text.strip()\n",
    "\n",
    "        try:\n",
    "            response_data = json.loads(raw_response)\n",
    "            # Ensure status is always present, fallback to \"normal\"\n",
    "            status = response_data.get(\"status\", \"normal\")\n",
    "            response_data[\"status\"] = status  # Set status if missing\n",
    "            self.current_status = status  # Update status tracking\n",
    "            self.add_to_history(query, response_data[\"response\"])\n",
    "            return Response(**response_data)\n",
    "        except json.JSONDecodeError:\n",
    "            return Response(response=\"I'm not sure how to respond.\", status=\"normal\")\n",
    "\n",
    "\n",
    "# Order Management (Cart & Checkout)\n",
    "class OrderModule:\n",
    "    def __init__(self):\n",
    "        self.cart = {}\n",
    "\n",
    "    def add_to_cart(self, item, quantity=1):\n",
    "        \"\"\"Adds items to the cart.\"\"\"\n",
    "        if item in self.cart:\n",
    "            self.cart[item] += quantity\n",
    "        else:\n",
    "            self.cart[item] = quantity\n",
    "        return f\"Added {quantity}x {item} to your cart.\"\n",
    "\n",
    "    def view_cart(self):\n",
    "        \"\"\"View the current cart.\"\"\"\n",
    "        if not self.cart:\n",
    "            return \"Your cart is empty.\"\n",
    "        return \"\\n\".join([f\"{item}: {quantity}\" for item, quantity in self.cart.items()])\n",
    "    \n",
    "    def return_json(self):\n",
    "        return [{\"name\": k, \"quantity\": v} for k,v in self.cart.items()]\n",
    "\n",
    "    def confirm_order(self):\n",
    "        \"\"\"Finalizes the order and returns all ordered items in JSON format.\"\"\"\n",
    "        if not self.cart:\n",
    "            return Response(response=\"No items to order.\", status=\"done\", order_items={})\n",
    "\n",
    "        order_summary = self.cart.copy()\n",
    "        self.cart.clear()\n",
    "\n",
    "        return Response(\n",
    "            response=\"Order placed successfully! Is there anything else I can help you with?\",\n",
    "            status=\"done\",\n",
    "            order_items=order_summary\n",
    "        )\n",
    "\n",
    "\n",
    "class OrderingChatHandler:\n",
    "    def __init__(self, llm) -> None:\n",
    "        self.system_prompt = \"\"\n",
    "        self.convo_starter = \"What would you like to order\"\n",
    "        self.ask_more = \"Can I help you with anything else?\"\n",
    "        self.ask_instruction = \"Do you have any instructions?\"\n",
    "        self.order_str = \"\"\n",
    "        self.confirm_order = f\"Here is summary of your order: {self.order_str}\"\n",
    "        self.order = {}\n",
    "        self.llm = llm\n",
    "        self.history = []\n",
    "        self.status = 0\n",
    "        self.prev_response = None\n",
    "    \n",
    "    class Item(BaseModel):\n",
    "        name: str\n",
    "        quantity: int\n",
    "        \n",
    "    def process_query(self,query):\n",
    "        history_str = \"\\n\".join(self.history)\n",
    "        prompt = f\"\"\"\n",
    "                {SYSTEM_PROMPT}\n",
    "\n",
    "                Chat History:\n",
    "                {history_str}\n",
    "\n",
    "                Customer is trying to order something. Extract the order items from this customer response.\n",
    "\n",
    "                Follow JSON schema: {[Item.model_json_schema()]}\n",
    "                Ordered = 1 if the user ordered anything, 0 if not. Leave name \"NA\" and quantity 0 if the user did not order.\n",
    "                \n",
    "                User: {query}\n",
    "                \"\"\"\n",
    "        raw_response = llm.complete(prompt).text.strip()\n",
    "        try:\n",
    "            response_data = preprocess_and_parse(raw_response)\n",
    "            self.prev_response = response_data\n",
    "            if isinstance(response_data, list):\n",
    "                if int(response_data[0]['ordered']) == 1:\n",
    "                    self.status = 1\n",
    "                else:\n",
    "                    self.status = 0\n",
    "            else:\n",
    "                response_data = [response_data]\n",
    "            return response_data\n",
    "        except:\n",
    "            return {\"ordered\": 0, \"name\": \"NA\", \"quantity\": 0}\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "# Main conversation loop\n",
    "def conversation_loop():\n",
    "    order_system = OrderModule()\n",
    "    chat_handler = ChatHandler(llm=structured_llm)\n",
    "    order_chat_handler = OrderingChatHandler(llm=llm)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Customer: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        classification = chat_handler.process_query(user_input)\n",
    "        print(f\"AI: {classification}\")\n",
    "        \n",
    "            \n",
    "        if classification.status == \"ordering\":\n",
    "            # extract items using llm\n",
    "            print(\"ordering.....\")\n",
    "            while order_chat_handler.process_query(user_input)[0]['ordered']:\n",
    "            # items_ordered = user_input.lower().split(\" and \")  # Handling multiple items in one query\n",
    "                user_order = order_chat_handler.prev_response\n",
    "                for item in user_order:\n",
    "                    item_name = item[\"name\"]\n",
    "                    quantity = item[\"quantity\"]\n",
    "                    order_system.add_to_cart(item_name, quantity=quantity)\n",
    "                print(f\"--------\\n{order_system.view_cart()}\\n--------\")\n",
    "                user_input = input(\"do you need anything else?\")\n",
    "\n",
    "            print(\"--------Order done------\")\n",
    "            print(\"#### CART #####\")\n",
    "            print(order_system.return_json())\n",
    "            push_order(order=order_system.return_json())\n",
    "            ########\n",
    "            \n",
    "            \n",
    "            # Confirm order\n",
    "            \n",
    "            #########\n",
    "            # user_order = order_chat_handler.process_query(user_order)\n",
    "            # print(user_order)\n",
    "            # sys.exit(2)\n",
    "            # while True:\n",
    "            #     # Asking if the customer wants anything else\n",
    "            #     user_query = input(\"Customer (ordering): \")\n",
    "            #     classification = order_chat_handler.process_query(user_query)\n",
    "            #     print(classification.status)\n",
    "            #     if classification.status == \"done\":\n",
    "            #     #if user_query.lower() in [\"done\", \"checkout\", \"finish\"]:\n",
    "            #         order_response = order_system.confirm_order()\n",
    "            #         print(f\"AI: {order_response.response}\")\n",
    "            #         print(f\"Final Order: {json.dumps(order_response.order_items, indent=2)}\")\n",
    "\n",
    "            #         # Ask for the customer name and phone number\n",
    "            #         print(\"AI: What is your name?\")\n",
    "            #         name = input(\"What is your name? \")\n",
    "            #         print(\"AI: What is your Phone number?\")\n",
    "            #         phone_number = input(\"Can I have your phone number for the order? \")\n",
    "\n",
    "            #         # Store customer information\n",
    "            #         print(f\"Thank you, {name}. Your order has been placed. We will contact you at {phone_number} if necessary.\")\n",
    "            #         break\n",
    "            #     item_classification = chat_handler.process_query(user_query)\n",
    "\n",
    "            #     if item_classification.status != \"ordering\":\n",
    "            #         print(\"taking order\")\n",
    "            #         print(f\"AI: {item_classification.response}\")\n",
    "                    \n",
    "            #     else:\n",
    "            #         r = order_system.add_to_cart(user_query, quantity=1)\n",
    "            #         print(f\"added to cart: {r}\")\n",
    "            #         print(\"Cart:\", order_system.view_cart())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "Pass in structured llm for normal convo like before. Not for ordering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: response='Okay, one slider and one order of loaded fries. Will there be anything else?' status='ordering'\n",
      "ordering.....\n",
      "processed string: \n",
      "[\n",
      "  {\n",
      "    \"ordered\": 1,\n",
      "    \"name\": \"Slider\",\n",
      "    \"quantity\": 1\n",
      "  },\n",
      "  {\n",
      "    \"ordered\": 1,\n",
      "    \"name\": \"Loaded Fries\",\n",
      "    \"quantity\": 1\n",
      "  }\n",
      "]\n",
      "--------\n",
      "Slider: 1\n",
      "Loaded Fries: 1\n",
      "--------\n",
      "processed string: \n",
      "[\n",
      "  {\n",
      "    \"ordered\": 0,\n",
      "    \"name\": \"NA\",\n",
      "    \"quantity\": 0\n",
      "  }\n",
      "]\n",
      "--------Order done------\n",
      "#### CART #####\n",
      "[{'name': 'Slider', 'quantity': 1}, {'name': 'Loaded Fries', 'quantity': 1}]\n",
      "âœ… Order [{'name': 'Slider', 'quantity': 1}, {'name': 'Loaded Fries', 'quantity': 1}] added.\n",
      "AI: response='Okay, one slider and one order of loaded fries. That will be $20.98. Will there be anything else?' status='ordering'\n",
      "ordering.....\n",
      "processed string: \n",
      "[]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mconversation_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 196\u001b[39m, in \u001b[36mconversation_loop\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m classification.status == \u001b[33m\"\u001b[39m\u001b[33mordering\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# extract items using llm\u001b[39;00m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mordering.....\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43morder_chat_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mordered\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    197\u001b[39m     \u001b[38;5;66;03m# items_ordered = user_input.lower().split(\" and \")  # Handling multiple items in one query\u001b[39;00m\n\u001b[32m    198\u001b[39m         user_order = order_chat_handler.prev_response\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m user_order:\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "conversation_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
